import logging
import pandas as pd
import requests

from airflow import DAG
from airflow.models import Variable
from airflow.operators.empty import EmptyOperator
from airflow.operators.python import PythonOperator
from airflow.datasets import Dataset
import pendulum

S3_FOOTBALL_DATASET = Dataset("s3://data-stack/raw/football")

OWNER = "15683"
SOURCE = "football-data.org"
COMPETITION = "CL"


def get_and_transfer_api_data_to_s3(**context):
    try:
        api_key = Variable.get("football_api_key")
        s3_access_key = Variable.get("access_key")
        s3_secret_key = Variable.get("secret_key")
    except KeyError:
        logging.error("Variables not found!")
        raise

    logical_date = context["logical_date"]
    date_str = logical_date.format("YYYY-MM-DD")

    logging.info(f"ğŸ“… Ğ”Ğ°Ñ‚Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (Logical Date): {date_str}")

    url = f"https://api.football-data.org/v4/competitions/{COMPETITION}/matches"
    headers = {"X-Auth-Token": api_key}

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        data = response.json()
        matches = data.get("matches", [])

        if not matches:
            logging.warning("API Ğ½Ğµ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¼Ğ°Ñ‚Ñ‡ĞµĞ¹. ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞº.")
            return

        df = pd.json_normalize(matches, sep='_')

        s3_path = f"s3://data-stack/raw/football/{date_str}/{COMPETITION}_matches.parquet"

        storage_options = {
            "key": s3_access_key,
            "secret": s3_secret_key,
            "endpoint_url": "http://minio:9000",
            "client_kwargs": {"use_ssl": False}
        }

        logging.info(f"ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ²: {s3_path}")
        df.to_parquet(s3_path, index=False, storage_options=storage_options)
        logging.info("âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾.")

    except Exception as e:
        logging.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        raise


with DAG(
        dag_id="raw_football_matches_from_api_to_s3",
        schedule_interval=None,  # None, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ
        start_date=pendulum.datetime(2025, 1, 1, tz="Europe/Moscow"),
        default_args={"owner": OWNER},
        tags=["s3", "raw", "football"],
        description="API -> S3 (Football)",
        catchup=False,
) as dag:
    start = EmptyOperator(task_id="start")

    task_transfer = PythonOperator(
        task_id="get_and_transfer_api_data_to_s3",
        python_callable=get_and_transfer_api_data_to_s3,
        outlets=[S3_FOOTBALL_DATASET],  # Ğ­Ñ‚Ğ¾ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ½ĞµÑ‚ Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ DAG
    )

    end = EmptyOperator(task_id="end")

    start >> task_transfer >> end

